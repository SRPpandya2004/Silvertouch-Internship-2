# -*- coding: utf-8 -*-
"""LSTM Tunning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kqJv6ctYO3lCvp7Yps48WS82C1Wvd4-P
"""

import pandas as pd

df = pd.read_csv('/content/sample_data/milk_production.csv')
print(df.head())
print(df.tail())

import numpy as np

values = df['Production'].values

# Normalize data (important for LSTM)
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
values_scaled = scaler.fit_transform(values.reshape(-1,1))

# Function to create sequences and labels
def create_sequences(data, seq_length):
    X = []
    y = []
    for i in range(len(data) - seq_length):
        X.append(data[i:i+seq_length])
        y.append(data[i+seq_length])
    return np.array(X), np.array(y)

SEQ_LENGTH = 30
X, y = create_sequences(values_scaled, SEQ_LENGTH)

print(X.shape, y.shape)  # (samples, timesteps, features)

split = int(0.8 * len(X))
X_train, X_val = X[:split], X[split:]
y_train, y_val = y[:split], y[split:]

import tensorflow as tf
from tensorflow.keras import layers, models

def build_model(units=200, dropout=0.8, learning_rate=0.1):
    model = models.Sequential()
    model.add(layers.LSTM(units, input_shape=(X_train.shape[1], X_train.shape[2])))
    model.add(layers.Dropout(dropout))
    model.add(layers.Dense(1))
    model.compile(
        loss='mse',
        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),
        metrics=['mse', 'mae']
    )
    return model

from sklearn.model_selection import ParameterGrid

param_grid = {
    'batch_size': [16, 32, 64],
    'epochs': [50, 100, 150]
}

for params in ParameterGrid(param_grid):
    model = build_model(units=128, dropout=0.2, learning_rate=0.01)
    print(f"Training with: batch_size={params['batch_size']}, epochs={params['epochs']}")

    history = model.fit(
        X_train, y_train,
        batch_size=params['batch_size'],
        epochs=params['epochs'],
        validation_data=(X_val, y_val),
        verbose=0
    )
    # Log or compare val_loss or val_accuracy here

import matplotlib.pyplot as plt

plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.title('Loss Curve')
plt.show()

import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error

# Predict on validation data
y_pred = model.predict(X_val)

# Inverse transform to get original scale
y_val_orig = scaler.inverse_transform(y_val)
y_pred_orig = scaler.inverse_transform(y_pred)

# Calculate metrics
mse = mean_squared_error(y_val_orig, y_pred_orig)
rmse = np.sqrt(mse)
print(f"MSE: {mse:.4f}")
print(f"RMSE: {rmse:.4f}")

# Plot actual vs predicted
plt.figure(figsize=(10,6))
plt.plot(y_val_orig, label='Actual')
plt.plot(y_pred_orig, label='Predicted')
plt.title('Actual vs Predicted')
plt.legend()
plt.show()

# Plot training and validation loss
plt.figure(figsize=(10,6))
plt.plot(history.history['loss'], label='Train Loss (MSE)')
plt.plot(history.history['val_loss'], label='Validation Loss (MSE)')
plt.title('Training and Validation Loss')
plt.legend()
plt.show()

"""# **Second Code**"""

# Cell 1: Imports & Environment Check
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, MaxPooling1D, Bidirectional, LSTM, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error

print("TensorFlow version:", tf.__version__)

# Cell 2: Load CSV & Inspect
df = pd.read_csv('/content/sample_data/milk_production.csv')
print(df.head())
print(df.tail())
print("\nColumns:", df.columns.tolist())

# Cell 3: Parse Dates & Set Index
# Adjust column names based on your CSV inspection above
df['Month']       = pd.to_datetime(df['Month'])
df.set_index('Month', inplace=True)
df = df.asfreq('MS')             # ensure a regular monthly frequency
df.columns = ['MilkProduction']  # rename for simplicity

plt.figure(figsize=(10,4))
plt.plot(df['MilkProduction'], label='Original')
plt.title('Monthly Milk Production')
plt.xlabel('Date')
plt.ylabel('Production')
plt.legend()
plt.show()

# Cell 4: Feature Engineering & Scaling
# Capture seasonality with sine/cosine of month
df['month']      = df.index.month
df['sin_month']  = np.sin(2 * np.pi * df['month']/12)
df['cos_month']  = np.cos(2 * np.pi * df['month']/12)

features = ['MilkProduction', 'sin_month', 'cos_month']
scaler   = MinMaxScaler()
data     = scaler.fit_transform(df[features])

# Cell 5: Sequence Creation
def create_sequences(arr, n_steps):
    X, y = [], []
    for i in range(len(arr) - n_steps):
        X.append(arr[i:i+n_steps])
        y.append(arr[i+n_steps, 0])
    return np.array(X), np.array(y)

n_steps = 12
X, y    = create_sequences(data, n_steps)
print("X shape:", X.shape, "| y shape:", y.shape)

# Cell 6: Train–Validation Split
split = int(0.8 * len(X))
X_train, X_val = X[:split], X[split:]
y_train, y_val = y[:split], y[split:]

print("Train:", X_train.shape, y_train.shape)
print("Val:  ", X_val.shape, y_val.shape)

# Cell 7: Build CNN–BiLSTM Hybrid Model
n_features = X.shape[2]

model = Sequential([
    Conv1D(64, kernel_size=3, activation='relu',
           input_shape=(n_steps, n_features)),
    MaxPooling1D(pool_size=2),
    Bidirectional(LSTM(128, dropout=0.2,
                       recurrent_dropout=0.1)),
    Dense(1)
])

model.compile(optimizer=Adam(1e-3), loss='mse')
model.summary()

# Cell 8: Train with Callbacks
callbacks = [
    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),
    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)
]

history = model.fit(
    X_train, y_train,
    epochs=400,
    batch_size=16,
    validation_data=(X_val, y_val),
    callbacks=callbacks,
    verbose=1
)

plt.figure(figsize=(8,4))
plt.plot(history.history['loss'], label='train loss')
plt.plot(history.history['val_loss'], label='val loss')
plt.title('Training vs Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('MSE')
plt.legend()
plt.show()

# Cell 9: Invert Scaling & Compute Metrics
# Predict on validation set
y_pred_scaled = model.predict(X_val)

# Build dummy arrays to invert only the first column
inv_dummy = np.zeros((len(y_pred_scaled), n_features))
inv_dummy[:,0] = y_pred_scaled[:,0]
y_pred = scaler.inverse_transform(inv_dummy)[:,0]

true_dummy = np.zeros((len(y_val), n_features))
true_dummy[:,0] = y_val
y_true = scaler.inverse_transform(true_dummy)[:,0]

# Calculate errors
mse  = mean_squared_error(y_true, y_pred)
rmse = np.sqrt(mse)
mae  = mean_absolute_error(y_true, y_pred)
print(f"MSE: {mse:.3f} | RMSE: {rmse:.3f} | MAE: {mae:.3f}")

# Cell 10: Plot Actual vs Predicted
dates = df.index[-len(y_true):]

plt.figure(figsize=(10,4))
plt.plot(dates, y_true, label='Actual', linewidth=2)
plt.plot(dates, y_pred, label='Predicted', linewidth=2, alpha=0.8)
plt.title('Milk Production: Actual vs Predicted')
plt.xlabel('Date')
plt.ylabel('Production')
plt.legend()
plt.show()

pip install keras-tuner

"""# **Third Code**"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import (
    Input, Conv1D, MaxPooling1D,
    Bidirectional, LSTM, Dense,
    Dropout, Activation, Flatten,
    Permute, Multiply, RepeatVector,
    Lambda
)
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping

from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error

import keras_tuner as kt

# Load & preprocess
df = pd.read_csv('/content/sample_data/milk_production.csv')
df['Month'] = pd.to_datetime(df['Month'])
df.set_index('Month', inplace=True)
df = df.asfreq('MS')
df.columns = ['Milk']

# add seasonality
df['sin_m'] = np.sin(2*np.pi*df.index.month/12)
df['cos_m'] = np.cos(2*np.pi*df.index.month/12)

# scale
scaler = MinMaxScaler()
arr    = scaler.fit_transform(df[['Milk','sin_m','cos_m']])

# sequence builder
def make_seqs(data, n_steps=12):
    X, y = [], []
    for i in range(len(data)-n_steps):
        X.append(data[i:i+n_steps])
        y.append(data[i+n_steps,0])
    return np.array(X), np.array(y)

n_steps = 12
X, y    = make_seqs(arr, n_steps)

# train/validation split
split = int(0.8 * len(X))
X_tr, X_va = X[:split], X[split:]
y_tr, y_va = y[:split], y[split:]
n_feats = X.shape[2]

def build_tuned_model(hp):
    inp = Input(shape=(n_steps, n_feats))

    # Tune number of Conv1D filters and kernel size
    filters    = hp.Choice('conv_filters', [32, 64, 128])
    kernel     = hp.Choice('kernel_size', [3, 5])
    x = Conv1D(filters, kernel, activation='relu')(inp)
    x = MaxPooling1D(2)(x)

    # Tune LSTM units
    lstm_units = hp.Int('lstm_units', min_value=64, max_value=256, step=64)
    x = Bidirectional(
        LSTM(lstm_units, return_sequences=True)
    )(x)

    # Attention block (static)
    e     = Dense(1, activation='tanh')(x)
    e     = Flatten()(e)
    alpha = Activation('softmax')(e)
    alpha = RepeatVector(x.shape[-1])(alpha)
    alpha = Permute([2, 1])(alpha)
    x     = Multiply()([x, alpha])
    x     = Lambda(lambda t: tf.reduce_sum(t, axis=1))(x)

    # Tune dropout rate
    dr   = hp.Float('dropout', 0.1, 0.5, step=0.1)
    x    = Dropout(dr)(x)
    out  = Dense(1)(x)

    model = Model(inp, out)

    # Tune learning rate
    lr = hp.Float('learning_rate', 1e-4, 1e-2, sampling='log')
    model.compile(
        optimizer=Adam(lr),
        loss='mse'
    )
    return model

tuner = kt.Hyperband(
    build_tuned_model,
    objective='val_loss',
    max_epochs=50,
    factor=3,
    directory='milk_tuner',
    project_name='cnn_bilstm_attention'
)

# Early stopping to speed up bad trials
stop_early = EarlyStopping(monitor='val_loss', patience=5)

tuner.search(
    X_tr, y_tr,
    epochs=50,
    validation_data=(X_va, y_va),
    callbacks=[stop_early],
    batch_size=16,
    verbose=2
)


# Summarize results
tuner.results_summary()

# Get the top model
best_model = tuner.get_best_models(num_models=1)[0]

# Predict & invert scale
y_pred_s = best_model.predict(X_va)
dummy    = np.zeros((len(y_pred_s), n_feats))
dummy[:,0] = y_pred_s[:,0]
y_pred = scaler.inverse_transform(dummy)[:,0]

true_dummy = np.zeros((len(y_va), n_feats))
true_dummy[:,0] = y_va
y_true = scaler.inverse_transform(true_dummy)[:,0]

# Compute metrics
mse  = mean_squared_error(y_true, y_pred)
rmse = np.sqrt(mse)
print(f"Best model RMSE: {rmse:.2f}")

dates = df.index[-len(y_true):]

plt.figure(figsize=(12,4))
plt.plot(dates, y_true, label='Actual',   linewidth=2)
plt.plot(dates, y_pred, label='Predicted', linewidth=2, alpha=0.8)
plt.title(f'Milk Production Forecast (Tuned Model)\nRMSE={rmse:.2f}')
plt.xlabel('Date'); plt.ylabel('Production')
plt.legend(); plt.grid(True); plt.show()

